{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c9d6c-cb8c-46b1-b557-4479e39335dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "import numpy as np\n",
    "import random, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c6de8-5648-4160-803a-7507f411f39c",
   "metadata": {},
   "source": [
    "## Source for the dataset : https://www.deepsig.ai/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091412d2-46c2-402d-b8f3-811fe01bddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = cPickle.load(open(\"Add the PATH to the FILE\",'rb'), encoding='latin1')\n",
    "snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])\n",
    "\n",
    "BPSK = Xd[('BPSK',18)][0:800,:,:]\n",
    "QPSK = Xd[('QPSK',18)][0:800,:,:]\n",
    "EPSK = Xd[('8PSK',18)][0:800,:,:]\n",
    "\n",
    "X = np.vstack((BPSK,QPSK,EPSK))\n",
    "\n",
    "BPSK_TEST = Xd[('BPSK',18)][800:1000,:,:]\n",
    "QPSK_TEST = Xd[('QPSK',18)][800:1000,:,:]\n",
    "EPSK_TEST = Xd[('8PSK',18)][800:1000,:,:]\n",
    "test = np.vstack((BPSK_TEST,QPSK_TEST,EPSK_TEST))\n",
    "\n",
    "b = np.zeros(800)\n",
    "q = np.ones(800)\n",
    "e = np.empty(800)\n",
    "e.fill(2)\n",
    "lbl = np.hstack((b,q,e))\n",
    "\n",
    "btest = np.zeros(200)\n",
    "qtest = np.ones(200)\n",
    "etest = np.empty(200)\n",
    "etest.fill(2)\n",
    "lbltest = np.hstack((btest,qtest,etest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0975316e-db3e-4cf0-933c-65893fec7593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 21:51:13.555787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2022.3.1/oneapi/vpl/2022.2.5/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/tbb/2021.7.1/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/mpi/2021.7.1//libfabric/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/mpi/2021.7.1//lib/release:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/mpi/2021.7.1//lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/mkl/2022.2.1/lib/intel64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/itac/2021.7.1/slib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ipp/2021.6.2/lib/intel64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ippcp/2021.6.2/lib/intel64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ipp/2021.6.2/lib/intel64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/dnnl/2022.2.1/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/debugger/2021.7.1/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/debugger/2021.7.1/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/debugger/2021.7.1/dep/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/dal/2021.7.1/lib/intel64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/compiler/2022.2.1/linux/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/compiler/2022.2.1/linux/lib/x64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/compiler/2022.2.1/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/compiler/2022.2.1/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ccl/2021.7.1/lib/cpu_gpu_dpcpp:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/vpl/2022.2.5/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/tbb/2021.7.1/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/mpi/2021.7.1//libfabric/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/mpi/2021.7.1//lib/release:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/mpi/2021.7.1//lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/mkl/2022.2.1/lib/intel64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/itac/2021.7.1/slib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ipp/2021.6.2/lib/intel64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ippcp/2021.6.2/lib/intel64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ipp/2021.6.2/lib/intel64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/dnnl/2022.2.1/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/debugger/2021.7.1/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/debugger/2021.7.1/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/debugger/2021.7.1/dep/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/dal/2021.7.1/lib/intel64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/compiler/2022.2.1/linux/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/compiler/2022.2.1/linux/lib/x64:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/compiler/2022.2.1/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/compiler/2022.2.1/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2022.3.1/oneapi/ccl/2021.7.1/lib/cpu_gpu_dpcpp\n",
      "2022-12-01 21:51:13.555872: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e112b4-3f16-418b-a6e2-6afb6e05c765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 2, 128)\n",
      "(2400,)\n",
      "(600, 2, 128)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 3\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 2, 128\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "x_train = X\n",
    "y_train = lbl\n",
    "x_test = test\n",
    "y_test = lbltest\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb2e5b9-19be-4f7f-a72f-aa406b4e8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7336247-375f-4a24-9f4a-45457b0940fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4aec3d3-18d5-40ba-b5d7-ccf489f68b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2400, 2, 128, 1)\n",
      "2400 train samples\n",
      "600 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb06f7b-4c09-4fe3-b5b5-48ba9cb9887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a79d2-ba45-41ff-921f-5096135a8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767adb6-2440-4afa-84da-fe96a570ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(1, 2),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "dr = 0.5 # dropout rate (%)\n",
    "model.add(ZeroPadding2D((0, 2)))\n",
    "model.add(Conv2D(256, (1, 3), padding='valid', activation=\"relu\", name=\"conv1\", kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(dr))\n",
    "model.add(ZeroPadding2D((0, 2)))\n",
    "model.add(Conv2D(80, (2, 3), padding=\"valid\", activation=\"relu\", name=\"conv2\", kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(dr))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', name=\"dense1\"))\n",
    "model.add(Dropout(dr))\n",
    "model.add(Dense(num_classes, name=\"dense2\" ))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97321230-b292-4efc-8f9e-23c4de7d9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf0d92-773c-481f-b8e3-3e3263354a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history=model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_split = 0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a86eb0c-8aea-4da1-bb66-1ac75eb27552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df7950-2f3e-4c1c-9ef6-3e35e0ed9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c949c-dff5-4474-8c01-ae1dd492b019",
   "metadata": {},
   "source": [
    "## Trying out a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e9acc8-ea40-4683-a3d6-41a8a19e2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(32, kernel_size=(1, 2),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "dr = 0.25 # dropout rate (%)\n",
    "model_1.add(ZeroPadding2D((0, 2)))\n",
    "model_1.add(Conv2D(256, (1, 3), padding='valid', activation=\"elu\", name=\"conv1\"))\n",
    "model_1.add(Dropout(dr))\n",
    "model_1.add(ZeroPadding2D((0, 2)))\n",
    "model_1.add(Conv2D(128, (2, 3), padding=\"valid\", activation=\"elu\", name=\"conv2\"))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Dropout(dr))\n",
    "model_1.add(Conv2D(32, (1, 2), activation='elu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "#model_1.add(Dense(32, activation='relu'))\n",
    "model_1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_1.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "              metrics=['accuracy'])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40519e89-a16e-410f-a71f-c56ddfd804a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1=model_1.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          verbose=1,\n",
    "          validation_split = 0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2912841e-492b-4fe6-a73c-d0d3ded8102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "189781d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40db9722-bc0f-424e-b2fc-e4c1c724fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder_model(input_shape):\n",
    "    model_input = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    encoder = Conv2D(32, kernel_size=(1, 2), padding='same', input_shape=input_shape)(model_input)\n",
    "    encoder=Dropout(0.25)(encoder)\n",
    "    #encoder = BatchNormalization()(encoder)\n",
    "    encoder = Activation(activation='relu')(encoder)\n",
    "\n",
    "    encoder = Conv2D(64, kernel_size=(2, 3), padding='same')(encoder)\n",
    "    encoder=Dropout(0.25)(encoder)\n",
    "    #encoder = BatchNormalization()(encoder)\n",
    "    encoder = Activation(activation='relu')(encoder)\n",
    "    encoder = MaxPooling2D(pool_size=(1, 3))(encoder)\n",
    "\n",
    "    encoder = Flatten()(encoder)\n",
    "    encoder = Dense(128)(encoder)\n",
    "    #encoder = BatchNormalization()(encoder)\n",
    "    encoder=Dropout(0.25)(encoder)\n",
    "    encoder = Activation(activation='relu')(encoder)\n",
    "\n",
    "    return Model(model_input, encoder)\n",
    "\n",
    "\n",
    "def create_decoder_model(embedding_shape):\n",
    "    embedding_a = tf.keras.layers.Input(shape=encoder_model.output_shape)\n",
    "    decoder = Dense(2*128*1)(embedding_a)\n",
    "    decoder = Activation(activation='relu')(decoder)\n",
    "    decoder = Reshape(input_shape)(decoder)\n",
    "\n",
    "    return Model(embedding_a, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39e4a61c-4b6a-4a4d-9cac-430f6d7e1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = create_encoder_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf226212-c146-4d13-8fcd-99e60be9e700",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 2, 128, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 2, 128, 32)        96        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 128, 32)        0         \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 2, 128, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 2, 128, 64)        12352     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2, 128, 64)        0         \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 2, 128, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 2, 42, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 5376)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               688256    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 701,216\n",
      "Trainable params: 700,960\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c95882df-d31b-4fe2-9213-f676b8e44d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5501a8b-b999-459c-bcff-2d066818cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = create_decoder_model(encoder_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba81baff-a642-4ebb-9467-b5990239e6a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None, 128)]       0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, None, 256)         33024     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, None, 256)         0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 2, 128, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,024\n",
      "Trainable params: 33,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6af849d-0546-4505-9b5d-615d8392fd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 128), dtype=tf.float32, name='input_22'), name='input_22', description=\"created by layer 'input_22'\"), but it was called on an input with incompatible shape (None, 128).\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "epochs = 10\n",
    "\n",
    "encoder_model = create_encoder_model(input_shape)\n",
    "decoder_model = create_decoder_model(encoder_model.output_shape)\n",
    "autoencoder_network = AutoEncoder(encoder_model, decoder_model)\n",
    "autoencoder_network.compile(loss=tf.keras.losses.categorical_crossentropy, \n",
    "                            optimizer=tf.keras.optimizers.Adam(clipvalue=0.1), \n",
    "                            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "120bdaca-1e17-4f53-b2f7-f0de68c7a727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 128), dtype=tf.float32, name='input_22'), name='input_22', description=\"created by layer 'input_22'\"), but it was called on an input with incompatible shape (None, 128).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 128), dtype=tf.float32, name='input_22'), name='input_22', description=\"created by layer 'input_22'\"), but it was called on an input with incompatible shape (None, 128).\n",
      "19/19 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00WARNING:tensorflow:Model was constructed with shape (None, None, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 128), dtype=tf.float32, name='input_22'), name='input_22', description=\"created by layer 'input_22'\"), but it was called on an input with incompatible shape (None, 128).\n",
      "19/19 [==============================] - 1s 45ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "autoencoder_network.fit(x_train, x_train,\n",
    "                        validation_data=(x_test, x_test),\n",
    "                        batch_size=128,\n",
    "                        epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce53d1f-2f24-4a2e-b955-14c86061a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = encoder_model.outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c835c354-2633-49be-a51f-b780534f479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Dense(num_classes)(embedding)\n",
    "embedding = BatchNormalization()(embedding)\n",
    "embedding = Activation(activation='sigmoid')(embedding)\n",
    "\n",
    "model = Model(encoder_model.inputs[0], embedding)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7544c8de-003f-45bd-8a98-c8e339a3e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db887e-3c09-422a-9d93-6621e14ebbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
